\chapter{Introduction}

A \emph{Centralized System} is one in which the core functionality of the
system is dictated by a single body that single-handedly determines the use and
behavior of the system. Any privacy guarantees are at the sole discretion of the
system.

Users of Centralized Systems have no inherent guarantee of \emph{privacy} for 
their data. How their data is collected and used is at the sole discretion of
the service. Services often offer vague claims as to their privacy guarantees
for users.

This thesis presents multiple avenues of research providing mechanisms for
Centralized Systems to offer services with guaranteed privacy. These services
are built upon privacy proofs which guarantee they limit information shared
between users and the services and have the smallest possible surface area
allowing these Centralized Systems to provably guarantee their services are
fully enabling user privacy.

In order to develop these tools which guarantee user privacy there must be a
basis of what information is necessary for a service to function as well as how
potential bad acting Centralized Systems abuse the service they offer to
restrict access to the content they offer.

The concept of user privacy is inherently linked to the concept of service
provider censorship. A service with no user privacy can censor a users access to
content through that lack of privacy. By guaranteeing user privacy we restrict
the possibility of a service censoring content to users. We delve into more
details on this now.

\section{Content Provider Censorship}
Online censorship is done in many ways. In addition to blocking access to
websites, censors also use legal means to remove information from content
providers directly, such as through laws like the DMCA~\cite{dmca} in the United
States. In the second half of 2016, Twitter received over 5,000 removal requests
from government and police agencies worldwide, and complied with 19\% of
them~\cite{twitter-transparency}. In one example from August 2016, Twitter
complied with a Brazilian government request to remove a tweet comparing
then-mayoral candidate Rafael Greca to a fictional villain from the 1992 film
Batman Returns~\cite{twitter-rafael-greca}.
% https://www.lumendatabase.org/notices/12866354

Services can be compelled (politically or financially) to censor content for
some subset of users which makes the censorship less overt: the content is
available for some users but not others. 

Enhancing user privacy can enable censorship-resistant content providers to not
censor content. A service that is unaware of the content being requested cannot
censor access solely to that content. This is the framework of the work
presented in \Cref{ch:poc}: \emph{Proof of Censorship: Enabling centralized
censorship-resistant content providers}.

Using Private Information Retrieval (PIR) a content provider is unaware of the
content a user is requesting thereby inhibiting its ability to censor access to
a subset of content. The provider must censor access to the service as a whole
or not at all.

\emph{Proof of Censorship} extends this functionality by guaranteeing the
content has not been modified by providing a proof the content has not been
modified since upload time.

This further enables services to purposely remove content against its policies,
users receive proof that the content has been removed (or modified) that the
service can publicly announce.

\section{Metadata Privacy}
Basically the intro to signal

\section{Measurement of censorship in existing systems}
Basically the intro to Mind the IP Gap

\section{Thesis Structure}
In this thesis we provide three projects geared towards enhancing Privacy in
Centralized Systems:

\begin{enumerate}
    \item Proof of Censorship --- We showcase content provider censorship and
    how a service dedicated to not censoring its users can implement a service
    with privacy guarantees that users content will not be removed or altered by
    the service.
    \item Improving Signal's Sealed Sender --- We build on Signal's Sealed
    Sender which promises its users the privacy of not knowing which user is
    messaging which users but ultimately is vulnerable to a simple Statistical
    Disclosure Attack allowing Signal (if compelled or malicious) to determine
    who a user is messaging. This work provides a provably private mechanism to
    ensure any centralized messaging service can offer its service without
    learning metadata information about which users are messaging each other.
    \item Mind the IP Gap --- We measure how countries censor access to the
    internet through DNS resolution over the IPv4 and IPv6 internet allowing
    future work to implement systems allow censored citizens to circumvent
    countries DNS censorship techniques.
\end{enumerate}