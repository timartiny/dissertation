\chapter{Introduction}

A \emph{Centralized System} is one in which the core functionality of the
system is dictated by a single body that single-handedly determines the use and
behavior of the system. Any privacy guarantees are at the sole discretion of the
system.

Users of Centralized Systems have no inherent guarantee of \emph{privacy} for 
their data. How their data is collected and used is at the sole discretion of
the service. Services often offer vague claims as to their privacy guarantees
for users.

This thesis presents multiple avenues of research providing mechanisms for
Centralized Systems to offer services with guaranteed privacy. These services
are built upon privacy proofs which guarantee they limit information shared
between users and the services and have the smallest possible surface area
allowing these Centralized Systems to provably guarantee their services are
fully enabling user privacy.

In order to develop these tools which guarantee user privacy there must be a
basis of what information is necessary for a service to function as well as how
potential bad acting Centralized Systems abuse the service they offer to
restrict access to the content they offer.

The concept of user privacy is inherently linked to the concept of service
provider censorship. A service with no user privacy can censor a users access to
content through that lack of privacy. By guaranteeing user privacy we restrict
the possibility of a service censoring content to users. We delve into more
details on this now.

\section{Content Provider Censorship}
Online censorship is done in many ways. In addition to blocking access to
websites, censors also use legal means to remove information from content
providers directly, such as through laws like the DMCA~\cite{dmca} in the United
States. In the second half of 2016, Twitter received over 5,000 removal requests
from government and police agencies worldwide, and complied with 19\% of
them~\cite{twitter-transparency}. In one example from August 2016, Twitter
complied with a Brazilian government request to remove a tweet comparing
then-mayoral candidate Rafael Greca to a fictional villain from the 1992 film
Batman Returns~\cite{twitter-rafael-greca}.
% https://www.lumendatabase.org/notices/12866354

Services can be compelled (politically or financially) to censor content for
some subset of users which makes the censorship less overt: the content is
available for some users but not others. 

Enhancing user privacy can enable censorship-resistant content providers to not
censor content. A service that is unaware of the content being requested cannot
censor access solely to that content. This is the framework of the work
presented in \Cref{ch:poc}: \emph{Proof of Censorship: Enabling centralized
censorship-resistant content providers}.

Using Private Information Retrieval (PIR) a content provider is unaware of the
content a user is requesting thereby inhibiting its ability to censor access to
a subset of content. The provider must censor access to the service as a whole
or not at all.

\emph{Proof of Censorship} extends this functionality by guaranteeing the
content has not been modified by providing a cryptographic proof the content has
not been modified since upload time.

This further enables services to purposely remove content against its policies,
users receive proof that the content has been removed (or modified) that the
service can publicly announce.

\section{Metadata Privacy}
While leaking metadata may appear reasonable when compared to revealing the
contents of the messages, observing metadata can have serious consequences.
Consider that Alice may be a whistleblower communicating with a journalist
\cite{190976} or a survivor of domestic abuse seeking confidential support
\cite{236244}. In these cases, merely knowing \emph{to whom} Alice is
communicating combined with other contextual information is often enough to
infer conversation content without reading the messages themselves. Former NSA
and CIA director Michael Hayden succinctly illustrated this importance of
metadata when he said the US government ``kill[s] people based on metadata''
\cite{haydenmetadata}.

In 2018 Signal, a secure end-to-end encrypted messenger, introduced Sealed
Sender\cite{sealed-sender}, a protocol that obscures the metadata associated
with encrypted messages by moving the ``From'' field of messages inside the
encrypted content, creating One-Way Anonymous messages.

On the whole this vastly increases the privacy of users of Signal. Clients using
Sealed Sender become private from an honest Signal service, as on the outside of
the ``encrypted envelope'' there is no notion of which Signal user is sending
messages.

In \Cref{ch:signal}: \emph{Improving Signal's Sealed Sender} we demonstrate that
the Sealed Sender protocol is vulnerable to a Statistical Disclosure Attack
(SDA), which would allow a malicious or compelled Signal (or other secure
end-to-end encrypted messengers that implement Sealed Sender) to link these
One-Way Anonymous messages due in part to delivery receipts: a feature of most
online messengers which immediately alert a user when their message has been
delivered.

We further develop a more private protocol by formalizing Sealed Sender
\emph{conversations} and decoupling a user's long term identity (such as Alice)
from the destination of messages, thereby creating a provably private One-Way
Anonymous message. We extend this framework to Two-Way Anonymous messages where
the messaging service need not know either the sender nor the receiver of a
message. 

\section{Measurement of censorship in existing systems}
Basically the intro to Mind the IP Gap

\section{Thesis Structure}
In this thesis we provide three projects geared towards enhancing Privacy in
Centralized Systems:

\begin{enumerate}
    \item Proof of Censorship --- We showcase content provider censorship and
    how a service dedicated to not censoring its users can implement a service
    with privacy guarantees that users content will not be removed or altered by
    the service.
    \item Improving Signal's Sealed Sender --- We build on Signal's Sealed
    Sender which promises its users the privacy of not knowing which user is
    messaging which users but ultimately is vulnerable to a simple Statistical
    Disclosure Attack allowing Signal (if compelled or malicious) to determine
    who a user is messaging. This work provides a provably private mechanism to
    ensure any centralized messaging service can offer its service without
    learning metadata information about which users are messaging each other.
    \item Mind the IP Gap --- We measure how countries censor access to the
    internet through DNS resolution over the IPv4 and IPv6 internet allowing
    future work to implement systems allow censored citizens to circumvent
    countries DNS censorship techniques.
\end{enumerate}