% \clearpage

\subsection{Security Definition for One-Way Sealed Sender Conversations}\label{sec:signal-apxdefinitions}

We now give a formal definition for one-way sealed sender conversations using a simulation based security definition.  We present the ideal functionality for one-way sealed sender conversations in \cref{fig:signal-definition}.  Importantly, this definition does not rule out learning information about the sender based on timing of sending messages, {\em e.g.} the sender's time zone.  We model the service provider as a party $\serviceprovider$ that can control delivery of messages and delivery receipts.  Note that the ideal functionality leaks the contents of the message $m$ to the service provider only if the receiver of that message is corrupted.  This models that if the service provider can decrypt the messages it is relaying, it may make delivery decisions based on knowledge of the plaintext.

We say that a protocol securely realizes this ideal functionality (in the stand alone model) if a corrupted service provider and an arbitrary number of corrupted users cannot determine if they are interacting in the {\em real experiment} or with the {\em ideal experiment} with non-negligible probability in the security parameter $\securityparameter$.  In the real experiment, the adversary starts by statically corrupting the service provider and any number of users.  Then, each honest user follows it own arbitrary strategy, interacting with the service provider using the protocol.  The corrupt parties can follow an adversarially chosen strategy.  In the ideal experiment, the adversary again begins by statically corrupting the service provider and any number of users.  Then, the honest players follow an arbitrary strategy but interact directly with the ideal functionality.  The service provider and corrupted users interact with a simulator $\sim,$ which mediates interaction between the adversary and the ideal functionality.  At the end of each experiment, a distinguisher algorithm takes in the views of the service provider and the corrupted parties and attempts to determine if the interaction was in the real experiment or the ideal experiment.  Note that because the simulator may not know which parties are interacting, it cannot leak this information to the adversary.

We denote the output of the ideal world experiment for any ideal world adversary $\sim$ and honest players with arbitrary strategies $P_H$ on inputs $x$ as $\mathsf{Ideal}_{P_H,\sim}(1^\lambda, x).$  We denote the output of the real experiment with adversary $\adversary$ running protocol $\Pi$ on input $x$ as $\mathsf{Real}_{P_H,\adversary,\Pi}(1^\lambda, x)$.  We say that a protocol $\Pi$ securely realizes the ideal functionality described in \cref{fig:signal-definition} if there exists a simulator $\sim$ such that 
$$\left|\mathsf{Ideal}_{P_H,\sim}(1^\lambda, x) - \mathsf{Real}_{P_H,\adversary,\Pi}(1^\lambda, x)\right| < \negl$$
